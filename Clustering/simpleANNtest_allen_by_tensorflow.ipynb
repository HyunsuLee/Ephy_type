{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow implementation for allen eletrophysiology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.loadtxt('cretrainX.csv', delimiter = ',')\n",
    "trainY = np.loadtxt('cretrainY.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.loadtxt('cretestX.csv', delimiter = ',')\n",
    "testY = np.loadtxt('cretestY.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 43])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([43, 20], stddev=0.01))\n",
    "# 입력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([20, 10], stddev=0.01))\n",
    "# L1 레이어의 출력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10, 2], stddev=0.01))\n",
    "# 최종 모델의 출력값은 W3 변수를 곱해 10개의 분류를 가지게 됩니다.\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'Avg. cost =', '0.691')\n",
      "('Epoch:', '0501', 'Avg. cost =', '0.184')\n",
      "('Epoch:', '1001', 'Avg. cost =', '0.145')\n",
      "('Epoch:', '1501', 'Avg. cost =', '0.134')\n",
      "('Epoch:', '2001', 'Avg. cost =', '0.065')\n",
      "('Epoch:', '2501', 'Avg. cost =', '0.067')\n",
      "('Epoch:', '3001', 'Avg. cost =', '0.031')\n",
      "('Epoch:', '3501', 'Avg. cost =', '0.041')\n",
      "('Epoch:', '4001', 'Avg. cost =', '0.009')\n",
      "('Epoch:', '4501', 'Avg. cost =', '0.044')\n",
      "('Epoch:', '5001', 'Avg. cost =', '0.021')\n",
      "('Epoch:', '5501', 'Avg. cost =', '0.021')\n",
      "('Epoch:', '6001', 'Avg. cost =', '0.011')\n",
      "('Epoch:', '6501', 'Avg. cost =', '0.025')\n",
      "('Epoch:', '7001', 'Avg. cost =', '0.013')\n",
      "('Epoch:', '7501', 'Avg. cost =', '0.006')\n",
      "('Epoch:', '8001', 'Avg. cost =', '0.005')\n",
      "('Epoch:', '8501', 'Avg. cost =', '0.004')\n",
      "('Epoch:', '9001', 'Avg. cost =', '0.002')\n",
      "('Epoch:', '9501', 'Avg. cost =', '0.012')\n",
      "('accuracy:', 0.91139245)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    batch_size = 128\n",
    "    total_batch = int(len(trainX) / batch_size)\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in range(10000):\n",
    "        total_cost = 0\n",
    "        for start, end in zip(range(0, len(trainX), batch_size), \n",
    "                             range(batch_size, len(trainX)+1, batch_size)):\n",
    "            _, cost_val = sess.run([optimizer, cost], feed_dict={X: trainX[start:end]\n",
    "                                                                  , Y: trainY[start:end]})\n",
    "            total_cost += cost_val\n",
    "        if (epoch % 500) == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    print('accuracy:', sess.run(accuracy,\n",
    "                        feed_dict={X: testX, Y: testY}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "267px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "345px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
