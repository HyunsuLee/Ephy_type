{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing for tensorflow\n",
    "## from newly prepared data from rserver by incheol.\n",
    "\n",
    "* 2018-2-26\n",
    "\n",
    "1. data load\n",
    "2. making one hot coding y-label\n",
    "3. minmax scaling\n",
    "4. save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './180226rdata/'\n",
    "save_path = './180228tensordata/'\n",
    "data_file_list = os.listdir(data_path)\n",
    "# data_name_list = [names[0:-4] for names in data_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file_name in data_file_list:\n",
    "    if file_name[0] == 'B':\n",
    "        data_frame = pd.read_csv(data_path+file_name)\n",
    "        data_frameX = data_frame.drop(['Unnamed: 0', 'binary_neuron'], axis = 1)\n",
    "        data_frameX = np.array(data_frameX)\n",
    "        np.savetxt(save_path + file_name[0:-4] + 'X.csv', data_frameX, delimiter = ',')\n",
    "        data_frameY = data_frame['binary_neuron']\n",
    "        data_frameY = np.array(data_frameY.str.contains('E').astype(int))\n",
    "        data_frameY = np.eye(2)[data_frameY]\n",
    "        np.savetxt(save_path + file_name[0:-4] + 'Y.csv', data_frameY, delimiter = ',')\n",
    "    else:\n",
    "        data_frame = pd.read_csv(data_path+file_name)\n",
    "        data_frameX = data_frame.drop(['Unnamed: 0', 'transgenic_line'], axis = 1)\n",
    "        data_frameX = np.array(data_frameX)\n",
    "        np.savetxt(save_path + file_name[0:-4] + 'X.csv', data_frameX, delimiter = ',')\n",
    "        data_frameY = data_frame['transgenic_line'].factorize()\n",
    "        data_frameY = np.array(data_frameY[0].astype(int))\n",
    "        data_frameY = np.eye(len(data_frameY), data_frameY.max() + 1)[data_frameY]\n",
    "        np.savetxt(save_path + file_name[0:-4] + 'Y.csv', data_frameY, delimiter = ',')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Btrain_longY.csv',\n",
       " 'Etrain_longY.csv',\n",
       " 'BtestX.csv',\n",
       " 'BtestY.csv',\n",
       " 'Btest_longX.csv',\n",
       " 'Btest_longY.csv',\n",
       " 'Btest_rampX.csv',\n",
       " 'Btest_rampY.csv',\n",
       " 'Btest_shortX.csv',\n",
       " 'Btest_shortY.csv',\n",
       " 'BtrainX.csv',\n",
       " 'BtrainY.csv',\n",
       " 'Btrain_longX.csv',\n",
       " 'Btrain_rampX.csv',\n",
       " 'Btrain_rampY.csv',\n",
       " 'Btrain_shortX.csv',\n",
       " 'Btrain_shortY.csv',\n",
       " 'EtestX.csv',\n",
       " 'EtestY.csv',\n",
       " 'Etest_longX.csv',\n",
       " 'Etest_longY.csv',\n",
       " 'Etest_rampX.csv',\n",
       " 'Etest_rampY.csv',\n",
       " 'Etest_shortX.csv',\n",
       " 'Etest_shortY.csv',\n",
       " 'EtrainX.csv',\n",
       " 'EtrainY.csv',\n",
       " 'Etrain_longX.csv',\n",
       " 'Etrain_rampX.csv',\n",
       " 'Etrain_rampY.csv',\n",
       " 'Etrain_shortX.csv',\n",
       " 'Etrain_shortY.csv',\n",
       " 'ItestX.csv',\n",
       " 'ItestY.csv',\n",
       " 'Itest_longX.csv',\n",
       " 'Itest_longY.csv',\n",
       " 'Itest_rampX.csv',\n",
       " 'Itest_rampY.csv',\n",
       " 'Itest_shortX.csv',\n",
       " 'Itest_shortY.csv',\n",
       " 'ItrainX.csv',\n",
       " 'ItrainY.csv',\n",
       " 'Itrain_longX.csv',\n",
       " 'Itrain_longY.csv',\n",
       " 'Itrain_rampX.csv',\n",
       " 'Itrain_rampY.csv',\n",
       " 'Itrain_shortX.csv',\n",
       " 'Itrain_shortY.csv']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordata_file_list = os.listdir(save_path)\n",
    "tensordata_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minmax_path = './180228tensordata_minmax/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file_name in tensordata_file_list:\n",
    "    if file_name[-5] == 'X' and file_name[1:3] == 'tr':\n",
    "        train_name = file_name\n",
    "        test_name = file_name[0] + 'test'+ file_name[6:]\n",
    "        train_dataX = np.loadtxt(save_path + train_name, delimiter = ',')\n",
    "        test_dataX = np.loadtxt(save_path + test_name, delimiter = ',')\n",
    "        minmax_scale = preprocessing.MinMaxScaler().fit(train_dataX)\n",
    "        train_dataX_minmax = minmax_scale.transform(train_dataX)\n",
    "        test_dataX_minmax = minmax_scale.transform(test_dataX)\n",
    "        np.savetxt(minmax_path + train_name[0:-4] + '_minmax.csv', \n",
    "                    train_dataX_minmax, delimiter = ',')\n",
    "        np.savetxt(minmax_path + test_name[0:-4] + '_minmax.csv', \n",
    "                    test_dataX_minmax, delimiter = ',')\n",
    "    elif file_name[-5] == 'Y':\n",
    "        dataY = np.loadtxt(save_path + file_name, delimiter = ',')\n",
    "        np.savetxt(minmax_path + file_name, dataY, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "523px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "343px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
